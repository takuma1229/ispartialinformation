{
    "os": "Linux-6.5.0-41-generic-x86_64-with-glibc2.35",
    "python": "3.12.3",
    "heartbeatAt": "2024-07-21T14:35:01.078534",
    "startedAt": "2024-07-21T14:34:59.922348",
    "docker": null,
    "cuda": null,
    "args": [],
    "state": "running",
    "program": "/home/takuma-s/Desktop/discourse_relation_explainability/src/fine-tuning.py",
    "codePathLocal": "src/fine-tuning.py",
    "codePath": "src/fine-tuning.py",
    "git": {
        "remote": "https://github.com/takuma1229/discourse_relation_explainability.git",
        "commit": "1f2003ab58357e1238d4deb870577048ab98c0dc"
    },
    "email": "takuma1229tennis@gmail.com",
    "root": "/home/takuma-s/Desktop/discourse_relation_explainability",
    "host": "takuma-s",
    "username": "takuma-s",
    "executable": "/home/takuma-s/Desktop/discourse_relation_explainability/.venv/bin/python",
    "cpu_count": 20,
    "cpu_count_logical": 28,
    "cpu_freq": {
        "current": 882.75375,
        "min": 800.0,
        "max": 4842.857142857143
    },
    "cpu_freq_per_core": [
        {
            "current": 800.0,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 800.751,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 1099.16,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 1100.0,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 1100.0,
            "min": 800.0,
            "max": 5400.0
        },
        {
            "current": 915.556,
            "min": 800.0,
            "max": 5400.0
        },
        {
            "current": 830.142,
            "min": 800.0,
            "max": 5400.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 5400.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 800.95,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 1012.074,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 800.779,
            "min": 800.0,
            "max": 5300.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        },
        {
            "current": 800.0,
            "min": 800.0,
            "max": 4200.0
        }
    ],
    "disk": {
        "/": {
            "total": 937.3305015563965,
            "used": 43.72850036621094
        }
    },
    "gpu": "NVIDIA GeForce RTX 4060 Ti",
    "gpu_count": 1,
    "gpu_devices": [
        {
            "name": "NVIDIA GeForce RTX 4060 Ti",
            "memory_total": 17175674880
        }
    ],
    "memory": {
        "total": 31.049339294433594
    }
}
