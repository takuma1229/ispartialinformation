Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tohoku-nlp/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Error executing job with overrides: ['is_debug=true', 'training.epochs=1', 'experiment_type=normal', 'model_name=tohoku-nlp/bert-base-japanese-v3']
Traceback (most recent call last):
  File "/home/takuma-s/Desktop/discourse_relation_explainability/src/fine_tuning.py", line 332, in main
    train_data = create_dataset(
                 ^^^^^^^^^^^^^^^
TypeError: create_dataset() missing 1 required positional argument: 'cfg'
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
num_added_tokens: 16, added_special_tokens: <NOUN>,<PRONOUN>,<ADJECTIVAL-NOUN>,<PRENOUN-ADJECTIVAL>,<ADVERB>,<CONJUNCTION>,<INTERJECTION>,<VERB>,<ADJECTIVE>,<AUXILIARY-VERB>,<PARTICLE>,<PREFIX>,<SUFFIX>,<SYMBOL>,<AUXILIARY-SYMBOL>,<BLANK>