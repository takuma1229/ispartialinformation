/content/drive/MyDrive/research_discourse_relation/discourse_relation_explainability
num_added_tokens: 16, added_special_tokens: <NOUN>,<PRONOUN>,<ADJECTIVAL-NOUN>,<PRENOUN-ADJECTIVAL>,<ADVERB>,<CONJUNCTION>,<INTERJECTION>,<VERB>,<ADJECTIVE>,<AUXILIARY-VERB>,<PARTICLE>,<PREFIX>,<SUFFIX>,<SYMBOL>,<AUXILIARY-SYMBOL>,<BLANK>
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/11 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
  0%|          | 0/5 [00:00<?, ?it/s] /usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()[00:00<?, ?it/s]
epoch: None 	loss: 0.065219   	accuracy: 0.2575 	precision: 0.1848 	recall: 0.2304 	f1: 0.1233
[2024-05-13 01:40:16,968] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (8)
[2024-05-13 01:40:16,968] torch._dynamo.convert_frame: [WARNING]    function: 'transpose_for_scores' (/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py:246)
[2024-05-13 01:40:16,968] torch._dynamo.convert_frame: [WARNING]    last reason: ___check_global_state()
[2024-05-13 01:40:16,968] torch._dynamo.convert_frame: [WARNING] To log all recompilation reasons, use TORCH_LOGS="recompiles".
[2024-05-13 01:40:16,968] torch._dynamo.convert_frame: [WARNING] To diagnose recompilation issues, see https://pytorch.org/docs/master/compile/troubleshooting.html.



  self.pid = os.fork()[00:00<?, ?it/s]
  self.pid = os.fork()[00:00<?, ?it/s]
  9%|▉         | 1/11 [00:00<00:03,  2.85it/s]
epoch: 0 	loss: 0.006990   	accuracy: 0.6315 	precision: 0.2488 	recall: 0.1819 	f1: 0.1858
  self.pid = os.fork()[00:00<?, ?it/s]





  self.pid = os.fork()[00:00<?, ?it/s]
 40%|████      | 2/5 [00:26<00:39, 13./usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()[00:00<?, ?it/s]
  1%|          | 1/84 [00:00<00:34,  2.43it/s]
epoch: 1 	loss: 0.005647   	accuracy: 0.7506 	precision: 0.2946 	recall: 0.2065 	f1: 0.1862





  self.pid = os.fork()[00:00<?, ?it/s]
  self.pid = os.fork()[00:00<?, ?it/s]
 12%|█▏        | 10/84 [00:01<00:09,  7.81it/s]
epoch: 2 	loss: 0.005008   	accuracy: 0.7513 	precision: 0.4175 	recall: 0.2052 	f1: 0.1831





  self.pid = os.fork()[00:00<?, ?it/s]
 80%|████████  | 4/5 [00:52<00:13, 13./usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()[00:00<?, ?it/s]
  1%|          | 1/84 [00:00<00:36,  2.30it/s]
epoch: 3 	loss: 0.004702   	accuracy: 0.7498 	precision: 0.3791 	recall: 0.2034 	f1: 0.1794





  self.pid = os.fork()[00:00<?, ?it/s]
  9%|▉         | 1/11 [00:00<00:03,  2.97it/s]
epoch: 4 	loss: 0.004627   	accuracy: 0.7491 	precision: 0.3505 	recall: 0.2025 	f1: 0.1776
  0%|          | 0/11 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
  0%|          | 0/11 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()

 82%|████████▏ | 9/11 [00:00<00:00, 19.99it/s]
OptimizedModule(
  (_orig_mod): BertForSequenceClassification(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(32784, 768)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-11): 12 x BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Linear(in_features=768, out_features=5, bias=True)
  )
)
<class 'torch._dynamo.eval_frame.OptimizedModule'>
<class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>