Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tohoku-nlp/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Error executing job with overrides: ['is_debug=true', 'training.epochs=1', 'experiment_type=normal', 'model_name=tohoku-nlp/bert-base-japanese-v3']
Traceback (most recent call last):
  File "/home/takuma-s/Desktop/discourse_relation_explainability/src/fine_tuning.py", line 332, in main
    train_data = create_dataset(
                 ^^^^^^^^^^^^^^^
  File "/home/takuma-s/Desktop/discourse_relation_explainability/src/process_data.py", line 127, in create_dataset
    dataset = CustomDataset(data, tokenizer, max_len, cfg.experiment_type)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/takuma-s/Desktop/discourse_relation_explainability/src/process_data.py", line 24, in __init__
    self.experiment_type = cfg.experiment_type
                           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'experiment_type'
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
num_added_tokens: 16, added_special_tokens: <NOUN>,<PRONOUN>,<ADJECTIVAL-NOUN>,<PRENOUN-ADJECTIVAL>,<ADVERB>,<CONJUNCTION>,<INTERJECTION>,<VERB>,<ADJECTIVE>,<AUXILIARY-VERB>,<PARTICLE>,<PREFIX>,<SUFFIX>,<SYMBOL>,<AUXILIARY-SYMBOL>,<BLANK>
!!!!!!!!!!!!!!!!!!!!!! warning. This is debug mode. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!